\documentclass{article}
\usepackage{proof}
\usepackage{bussproofs}
\usepackage{xcolor}
\usepackage{url}
\begin{document}
\title{Proofs for SMT Solvers}
\author{Arjun Viswanathan}
\date{}
\maketitle

\begin{abstract}
Satisfiability Modulo Theories (SMT) solvers input typically
large formulas that contain both Boolean logic and logic in 
different theories - such as arithmetic and strings - and 
decide whether 
the formulas are satisfiable or unsatisfiable. Verification 
tools use these solvers to prove system properties. As a 
result, solver output must be trustable. However, SMT solvers 
are really complicated tools that have tens of thousands of lines of code. One way to make SMT solver ouput more reliable is 
to have them produce proofs of their results. 
For satisfied formulas, this can be a model of 
satisfaction, that is, values for all the variables in the
formula. For unsatisfied formulas, it is a transformation of 
the formula into a simple contradiction using a small set of 
inference rules, checkable by an external tool such as a proof 
checker. This report describes the proof producing mechanisms 
commonly used SMT solvers and compares the proof systems 
of CVC4, VeriT, and Z3, three state-of-the-art SMT solvers.
\end{abstract}

\section{Introduction}
\label{sec:intro}
Boolean satisfiability, often called the SAT problem, 
is the problem of satisfying a Boolean formula, that is, 
consistently assigning values of True or False to the variables 
of the formula so that the entire formula evaluates to True. 
For example, \\ 
$(x \lor y) \land z$ \\
can be satisfied by the 
assignment $\{x=True,y=False,z=True\}$. On the other hand, \\
$x \land \neg x$ \\
is unsatisfiable, no matter what value is assigned to $x$.

Satisfiability Modulo Theories~\cite{DBLP:reference/mc/BarrettT18} or SMT 
lifts SAT to a level that includes theories. 
For example, \\
$(a = b) \land (b = c) \land \neg (a = c)$ \\
is a formula that is unsatisfiable in the theory of 
equality over uninterpreted functions. This is because, by
transitivity of $a = b$ and $b = c$, we have $a = c$. SMT 
allows us to be more expressive with our formulas, but 
this comes at the cost of more complicated decision 
procedures.

SMT solvers have plenty of applications in formal methods 
and software verification. For instance, SMT solvers are used 
in the back-end of model checkers~\cite{DBLP:books/daglib/0020348}, which input mathematical 
models of a software system, and verify whether they 
satisfy a particular property or not. Another area of 
application is symbolic
execution~\cite{DBLP:journals/csur/BaldoniCDDF18}, 
which is to analyze a 
program to figure out what set of inputs work for each 
part of the program. Other uses of SMT solvers include 
program synthesis~\cite{synth}, static analysis, 
and interpolant generation\textcolor{red}{REF}.

Given their rise in popularity and usage in the software 
verification world, it is really important that we are able 
to trust the outputs of SMT solvers. SMT solvers are typically 
very complex systems with tens of thousands of lines of code, 
liable to contain bugs. Verifying such a large codebase can 
be a cumbersome, if not impossible task. An alternative is 
to rely on tools called proof checkers~\cite{proofasst}, 
that have a much more trusted kernel that contain a small 
set of axioms and inference rules. These proof checkers 
sacrifice in automative capability what they gain in terms 
of trustability over SMT solvers. To exploit these proof 
checkers, SMT solvers produce proof certificates of their 
outputs, that can be checked by the proof checker.

In this report, I introduce the workings of an SMT solver 
and their proof producing capabilities; I also compare the 
proof formats of CVC4 and VeriT, two state-of-the-art SMT solvers. I begin by explain the algorithm that is at the core 
of most SMT solvers. I then explain the logical basis for 
proof production in SMT solvers, and then discuss the proof 
formats of the individual solvers.


\section{Formal Preliminaries}
\label{sec:prelim}
The following grammar specifies the syntax of the formulas we
will use: \\ 
$Variable\ \rightarrow\ x\ |\ y\ |\ ... $ \\
$Constant\ \rightarrow\ c_1\ |\ c_2\ |\ ... $ \\
$Term\ \rightarrow\ Variable\ |\ Constant\ |\ f(t_1, ..., t_n)$ \\
$Literal\ \rightarrow\ Term\ |\ \neg Term$ \\
$Formula\ \rightarrow\ True\ |\ False |\ p(t_1, ..., t_n)\ 
|\ Literal\ |\ Literal \lor Literal$ \\ 
$|\ Literal \land Literal\ |\ Literal \Rightarrow Literal\ |\ Literal \iff Literal$ \\
where $f$ is a function symbol and $p$ is a predicate symbol.

Functions can be understood as they are in basic mathematics, 
and predicates are functions to the Boolean type. Negation 
($\neg$), disjunction ($\lor$), conjunction ($\land$), implication ($\Rightarrow$), and double implication
($\iff$) have semantics as in classical logic~\cite{prop}.

Our setting consists of a background theory T consisting 
of m theories $T_1, ..., T_m$ with respective many-sorted 
signatures $\Sigma_1, ..., \Sigma_m$. All signatures share 
a set of sort (type) symbols, and equality is the only 
predicate. The theories also share a set of 
uninterpreted constants which are used for reasoning about 
terms that belong to multiple theories. 

This formalizes the fact that the framework here is 
described for a single theory, but that theory can 
be considered a combination of multiple theories~\cite{Manna2003}
\textcolor{red}{REF}.This means that formulas are 
composed of Boolean components, each of which will 
evaluate to True or False. However, since 
we have theories, these components could be just Boolean 
variables, or they could be (dis)equalities over our 
multiple theories, which gives us expressivity. 

For example, is over the theory of linear integer 
arithmetic (LIA) and the theory of 
equality over uninterpreted functions (EUF)
~\cite{LIAEUF}.\\
$(x \land y) \Rightarrow (a = 0 \land a + b = c \land 
\neg (f(b) = f(c)))$ \\
$x$ and $y$ are terms in the 
formula, and hence can only evaluate to True or False.
$a$, $b$, and $c$, on the other hand, are integer variables 
that must evaluate to an integer constant. To generalize 
this, we assume our theory T to be a combination of $m$ 
theories $T_1, ..., T_m$. Each theory $T_i$ is formally 
described by means of a signature $\Sigma_i$, but we 
will stick to intuitive theories such as the ones mentioned 
before, so we don't have to deal with such formalisms. A 
formal definition of theories and SMT can be found at 
~\cite{DBLP:reference/mc/BarrettT18}.

When it is used as a set, $\phi$ refers to the empty set. We also allow for representation of formulas that are 
conjunctions of conjuncts, as sets of the corresponding 
conjuncts. So we represent $c_1 \land ... \land c_n$ as
$\{c_1, ..., c_n\}$. This is a useful representation, 
since conjunction is commutative, associative, and 
repeating the number of times a conjunct occurs in a 
conjunction doesn't change the meaning of that conjunction, 
it only adds redundancy.

We have the notion of entailment on two levels. Propositional 
entailment: \\
$p \models_P q$ \\
read as ``formula $p$ propositionally entails formula $q$" says 
that $q$ is a logical consequence of $p$. For example, 
$a \land b \models_P a$, where a and b are Boolean 
variables. Entailment also occurs in a theory:
$x \models_i y$ \\
read as ``formula $x$ $i$-entails formula $y$". For example, 
$x > 3 \models_{LIA} x > 0$, where x is an integer variable.
If we abstracted these formulas to the propositional level, 
$m := x > 3$, and $n := x > 0$, 
the entailment $m \models_P n$ cannot be realized at the 
propositional level. We need reasoning at the level of 
the theory of arithmetic for this entailment to hold.

A formula is $satisfiable$ if we can consistently assign
values to all its variables (Boolean and theory), 
so that the formula evaluates to $True$. A formula is 
$unsatisfiable$ if there is no consistent assignment that 
we can give its variables so that the formula evaluates to 
$True$. $(x + y = 0) \land (m \lor n)$ is satisfiable, 
and a satisfying assignment is $\{x = 0, y = 0, m = True, 
n = False\}$. $p \land \neg p$ is unsatisfiable. Two formulas 
are $equisatisfiable$ if whenever one of them is satisfiable 
by an assignment, the same assignment satisfies the other. 
\textcolor{red}{Equisatisfiability}

A formula is $valid$, if no matter what values we assign its 
variables, it evaluates to $True$. In other words, it is
entailed form nothing. For example, \\
$\models_P p \lor \neg p$, and \\
$\models_{LIA} (x = 0) \lor (x < 0) \lor (x > 0)$.

Finally, the universal quantifier ($\forall$) and 
the existential quantifier ($\exists$) help us quantify 
variables in formulas. For example, $\forall x, x > 0 
\Rightarrow \neg (x < 0)$ states the obvious fact that 
positive numbers aren't negative, and $\exists x, y = 2x$ 
is the predicate that is true if $y$ is even. Our discussion 
in this report only involves quantifier-free logic of SMT 
solvers, but these are useful tools to have at the meta-level.


\section{The DPLL(T) Algorithm}
\label{sec:dpll}
Davis-Putnam-Logemann-Loveland or DPLL - named after its 
developers - is an algorithm developed in the 1960s 
for deciding the satisfiability of propositional formulas.
About half a century later, most SAT solvers and SMT solvers
are still based on some form of DPLL. All the solvers 
discussed in this work are DPLL(T) solvers, that is an 
extension of DPLL to accommodate theories. Section,
introduces the normal form required by these solvers, 
and Section explains the DPLL(T) algorithm as a 
transition system.

\subsection{CNF Conversion}
\label{sec:cnf}
SMT solvers require that the input formula is converted to a 
normal form called conjunctive normal form (CNF), before they 
start solving them. The CNF of a formula represents the 
formula as a conjunction of disjunctions. A clause is a 
disjunction (Boolean OR) of variables. So CNF is a 
conjunction (Boolean AND) of clauses. 

Using Tseitin clausification~\cite{BEL01Handbook}, any formula 
can be converted into an equisatisfiable CNF formula 
in linear time. Formulas F and G are equisatisfiable if 
every model that satisfies F also satisfies G and vice-versa.

The following is an example where a set of rewrite rules
are applied to F to convert it into CNF. \\
$F: a \Rightarrow (b \land c)$ \\
$Step\ 1: a \Rightarrow x_1 \land (x_1 \iff (b \land c))$ \\
$Step\ 2: x_2 \land (x_2 \iff a \Rightarrow x_1) \land 
(x_1 \iff (b \land c))$ \\
$Step\ 3: x_2 \land \\
(x_2 \Rightarrow (a \Rightarrow x_1) \land 
(a \Rightarrow x_1) \Rightarrow x_2) \land \\
(x_1 \Rightarrow (b \land c) \land 
(b \land c) \Rightarrow x_1)$ \\
$Step\ 4: x_2 \land \\
(\neg x_2 \lor \neg a \lor x_1) \land 
(a \lor x_2) \land (\neg x_1 \lor x_2) \land \\
(\neg x_1 \lor b) \land (\neg x_1 \lor c) \land 
(\neg b \lor \neg c \lor x_1)$ \\
Steps 1 and 2 involve introducing fresh variables $x_1$
and $x_2$ for all subterms of F by means of equivalence 
between the subterm and the fresh variable. Steps 3 and 4 
reduce these subterms to CNF by common rewrite rules 
such as distribution and De Morgan's law.


\subsection{Abstract DPLL(T) Framework}
\label{sec:trans}
DPLL(T) tries to satisfy the input formula - converted to 
CNF - by assigning truth values to terms so that it can
satisfy all input clauses. It is easy to satisfy a single
clause, because to satisfy a disjunction, it suffices to
assign one of the disjuncts to True. DPLL(T) carries out
assignments through logical reasoning, or by guessing. If a
guess leads to an unsuccessful assignment of the formula 
(a conflict), then the algorithm reverses the guess. 
If there are no more guesses to reverse, then the formula is
unsatisfiable.

DPLL(T) solvers can be formalized abstractly as 
state transition systems defined by a set of transition rules.\\
The states of a system are either
\begin{itemize}
	\item $fail$
	\item $\langle M, F, C \rangle$
\end{itemize}
$M$ is the current context, that is it is the current 
assignment of literals in the formula; a literal in M is 
preceded by a $\bullet$ if the literal was a decision, 
that is, it was guessed. 
If $M = M_0 \bullet M_1 \bullet ... \bullet M_n$, 
each $M_i$ is the decision level, and $M^{[i]}$ 
denotes $M_0 \bullet ... \bullet M_i$. \\
$F$ is a set of clauses representing some form of
the input formula in CNF. $C$ represents the conflict clause,
the clause from $F$ that is falsified by the assignment. \\
Initial state : $\langle \phi, F_0, \phi \rangle$, where $F_0$
is the input formula converted to CNF. \\
Final state:
\begin{itemize}
	\item $fail$, when $F_0$ is unsatisfiable in T.
	\item $\langle M, F, \Phi \rangle$ where $M$ is satisfiable in
	T, $F$ is equisatisfiable with $F_0$ in T, and $M \models_P F$.
\end{itemize}

%Each atom of a clause $F \cup C$ is pure, that is, it has a signature
%$\Sigma_i$ for some $i \in {1,...,m}$.
$Int_M$ is the set of all \textit{interface literals} of M:
the (dis)equalities between shared constants. \\
\textit{Shared constants} are the set represented by \\
$\{c\ |\ constant\ c\ occurs\ in\ Lit_{M|i} and Lit_{M|j}, 
for\ some 1 \leq i < j \leq m\}$. \\
$Lit_{M|i}$ consists of the $\Sigma_i$- literals of $Lit_M$. \\
These technicalities are necessary for solving of clauses 
that are a combination of multiple theories. 
For example, the term \\
$f(a) = 1 + x$ \\
combines the theory of equality over uninterpreted functions,
and that of arithmetic. Since each theory has its own solver,
this term that uses functions from both theories, must be 
purified for each theory solver, and this is done by means of
a shared constant. If the term is replaced by the following 
terms, \\
$f(a) = s_1, s_1 = 1 + x$ \\
we now have one term that is entirely over uninterpreted 
functions, and one over arithmetic ones. \\
Transition rules:
\begin{itemize}
	\item Propagate:\\ $\infer[Prop]{M := Ml}{l_1 \lor ... \lor l_n \lor l \in F 
		& \neg l_1,...,\neg l_n \in M & l, \neg l \notin M}$ 
	\item Decide:\\ $\infer[Dec]{M := M \bullet l}
	{l \in Lit_F \cup Int_M & l, \neg l \notin M}$ \\
	\item Conflict:\\ $\infer[Confl]{C:=\{l_1 \lor ... \lor l_N\}}
	{C = \phi & l_1 \lor ... \lor l_n \in F & \neg l_1,...,\neg l_n \in M}$ 
	\item Explain:\\ $\infer[Expl]{C := \{l_1 \lor ... \lor l_n \lor D\}}
	{C = \{\neg l \lor D\} & l_1 \lor ... \lor l_n \lor l \in F 
		& \neg l_1,...,\neg l_n \prec_M l}$
	\item Backjump:\\ $\infer[Backj]{C := \phi\ \ \ M := M^{[i]}l}
	{C = \{l_1 \lor ... \lor l_n \lor l\} & 
		lev\ \neg l_1, ... , lev\ \neg l_n \leq i < lev\ \neg l}$
	\item Learn: \\ $\infer[Learn]{F := F \cup C}{C \neq \phi}$
	\item Fail:\\ $\infer[Fail]{fail}{C \neq \phi & \bullet \notin M}$
\end{itemize}
The rules above model the behavior of the SAT engine, which treats atoms
as Boolean variables. Propagations allow us to assign 
literals that we are forced to assign by the logic. We 
might not always have this luxury; sometimes, we may have 
to make a guess on an assignment, and decisions let us do 
that. Propogations and/or decisions could lead us to 
a point where our current assignment conflicts with 
our goal of trying to satisfy the input formula. The 
Conflict rule recognizes this. If we encounter a conflict, 
and there were no previous decisions made, then we were 
forced by the logic to arrive at that conflict, so we 
conclude that the input formula is unsatisfiable. The Fail 
rule ensures this. If, there are previous decisions at
the time of conflict, then the Explain rule undoes 
propagations on top of conflicts, so we can get to a 
potentially wrong decision that we made, so we
can take the path down the opposite guess. Flipping a guess 
is handled by the Backjump rule. A conflict clause always 
consists of a formula that is entailed by the input formula. 
Explanations could have actually transformed the conflict 
clause into something that we didn't know that could actually
help us with future propagations. The Learn rule allows us 
to add a non-empty conflict clause to the input clauses to be 
satisfied. The rules that follow model the interaction between 
the SAT solver and the theory solvers.
\begin{itemize}
	\item $Propagate_i$ \\ $\infer[Prop_i]{M := Ml}	{l \in Lit_F \cup Int_M & 
		\models_i l_1 \lor ... \lor 
		l_n \lor l & \neg l_1, ..., \neg l_n \in M & l,\neg l \notin M}$ 
	\item $Conflict_i$ \\ $\infer[Confl_i]{C := \{l_1 \lor ... \lor l_n \}}
	{C = \phi & \models_i l_1 \lor ... \lor l_n & 
		\neg l_1, ..., \neg l_n \in M}$
	\item $Explain_i$ \\ $\infer[Expl_i]{C := \{l_1 \lor ... \lor l_n \lor D\}}
	{C = \{\neg l \lor D\} & \models_i l_1 \lor ... \lor l_n \lor l & 
		\neg\ l_1, ..., \neg\ l_n \prec_M l}$
	\item $Learn_i$ \\ $\infer[Learn_i]{F := F \cup \{l_1[\textbf{c}] 
		\lor ... \lor l_n[\textbf{c}]\}}
	{l_1,...,l_n \in Lit_{M|i} \cup Int_M \cup L_i & 
		\models_i \exists \textbf{x}(l_1[\textbf{x}] \lor ... 
		\lor l_n[\textbf{x}])}$ \\ where $\textbf{x}$ is a possibly empty 
	tuple of variables, and $\textbf{c}$ is a tuple of fresh constants 
	from $C$ - the set of shared constants between the sorts - of the
	same sort as $\textbf{x}$; $L_i$ is a finite set consisting of literals
	not present in the original formula $F$.
\end{itemize}
The rules maintain the invariant that every conflict clause and learned 
clause is entailed in T by the initial clause set.
These rules are analogous to their propositional rules, but 
have reasoning powers at the level of theories. For example, 
$x \land y$ is true at the propositional level, if both 
$x$ and $y$ are true. However, if the variables store these 
arithmetic theory literals: \\
$x = (a > 3)$ and $y = (a < 0)$, then $x \land y$ is 
unsatisfiable in the theory of arithmetic. So even though 
the $Conflict$ rule wont recognize this inconsistency, 
the $Conflict_{LIA}$ rule can recognize this, as long as 
the arithmetic solver is able to generate this fact as a 
$theory lemma$ which are facts that are true in the theory, 
generated in CNF form by the theory solvers. This example
as a lemma would look like this:
$\neg (a > 3) \lor \neg (a < 0)$ which would trigger the 
$Conflict_i$ clause given that $x$ and $y$ above are assigned 
to true, to satisfy $x \land y$. Thus, the $Propagate_i$, 
$Conflict_i$, $Explain_i$, and $Learn_i$ rule are similar 
to their propositional versions except that each rule is 
associated to a theory $i$ and operates on lemmas 
provided by that theory. 

For example, consider the formula F in CNF expressed as the set:\\
$\{a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b\}$
\begin{center}
	\begin{tabular}{l l l l l}
		\textbf{M} & \textbf{F} & \textbf{C} & \textbf{Rule} & \textbf{Step}\\
		\hline
		& $a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b$ & $\phi$ & Dec & 1 \\
		$\bullet a$ & $a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b$ & $\phi$ & Prop ($a \lor \neg b$) & 2 \\
		$\bullet a \neg b$ & $a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b$ & $\phi$ & Prop $(b \lor c)$ & 3 \\
		$\bullet a \neg b\ c$ & $a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b$ & $\phi$ & Confl $(\neg c \lor b)$ & 4 \\
		$\bullet a \neg b\ c$ & $a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b$ & $\neg c \lor b$ & Expl $(b \lor c)$ & 5 \\
		$\bullet a \neg b\ c$ & $a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b$ & $b$ & Expl $(\neg a \lor \neg b)$ & 6 \\
		$\bullet a \neg b\ c$ & $a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b$ & $\neg a$ & Learn $(\neg a)$ & 7\\
		$\bullet a \neg b\ c$ & $a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b, \neg a$ & $\neg a$ & Backj $(\neg a)$ & 8 \\
		$\neg a$ & $a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b, \neg a$ & $\phi$ & Prop $(a \lor \neg b)$ & 9 \\
		$\neg a \neg b$ & $a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b, \neg a$ & $\phi$ & Prop $(b \lor c)$ & 10 \\
		$\neg a \neg b\ c$ & $a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b, \neg a$ & $\phi$ & Confl $(\neg c \lor b)$ & 11 \\
		$\neg a \neg b\ c$ & $a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b, \neg a$ & $\neg c \lor b$ & Expl $(b \lor c)$ & 12 \\
		$\neg a \neg b\ c$ & $a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b, \neg a$ & $b$ & Expl $(a \lor \neg b)$ & 13\\
		$\neg a \neg b\ c$ & $a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b, \neg a$ & $a$ & Expl $(\neg a)$ & 14 \\
		$\neg a \neg b\ c$ & $a \lor \neg b, \neg a \lor \neg b, b \lor c, \neg c \lor b, \neg a$ & $\bot$ & Fail & 15 \\
	\end{tabular}
\end{center}

\textcolor{red}{THOERY EXAMPLE}

\section{DPLL(T) Proofs}
\label{sec:proofs}
This section describes the general framework used for a 
DPLL(T) solver to produce proofs for unsatisfiable formulas. 
A proof for a satisfiable formula is just a model that 
satisfies that formula, that is an assignment of values to 
the variables in the formula that make the formula evaluate 
to $True$. For an unsatisfiable formula, the proof involves 
transforming formula into a simple contradiction by means 
of proof rules or inference rules. 

An important rule is that of resolution, which is introduced 
in section, followed by a general explanation of how DPLL(T) 
solvers produce proofs of unsatisfiability in section.

\subsection{Propositional Resolution}
\label{sec:res}
Logical calculi operate by means of rules of inferences. A
rule of inference consists of a number of premises and a 
conclusion. The rule of inference specifies a schema for a 
logical calculus where, if the premises are true, then 
the conclusions are true. For example, \\
$\infer[modus\ ponens]{\psi}{\phi \Rightarrow \psi & \phi}$ \\
Modus ponens is a rule in classical logic that says that 
"if A implies B is true $and$ if A is true, then B is true".

The inference rule that is heavily used in construction of 
proofs for SMT solvers is propositional resolution. It is
stated as follows. \\
$\infer[resolution]{\phi_1 \lor ... \lor \phi_n \lor \psi_1 \lor ... \lor \psi_m}
{\phi_1 \lor ... \lor \phi_n \lor \chi & \neg \chi \lor \psi_1 \lor ... \lor \psi_m}$ \\

Assuming the usual interpretations of the conjunction
($\land$) and disjunction ($\lor$) in classical logic, the 
intuition behind the resolution rule is explained using the 
following instance of the resolution rule. \\
$\infer{a \lor c}{a \lor \neg b & b \lor c}$ \\
If the first premise is true, and $b$ is true - that is, 
$\neg b$ is false, then $a$ must be true. If the second 
premise is true, and $b$ is false, then $c$ must be true.
Now, both premises must be true for the conclusion to be true, 
and $b$ must be either true or false in classical logic. 
So, either $a$ must be true, or $c$ must be true, and this 
is the logical representation of our conclusion.

\subsection{DPLL(T) Proofs}
\label{sec:dplltproofs}

\section{Comparison of Solvers}
\label{sec:comp}
This section compares the proof systems of 3 state-of-the-art 
solvers CVC4, Z3, and VeriT as described in .

\section{Conclusion}
\label{sec:conc}

\bibliographystyle{abbrv}
\bibliography{bib}

\end{document}
